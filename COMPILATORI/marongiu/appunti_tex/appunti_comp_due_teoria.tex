\input{../../../preamble}

\title{%
Compilatori\\
\large Parte Due}

\begin{document}
\maketitle
\tableofcontents
\newpage
\section{Introduzione (25 feb)}

\subsection{Motivazione}

Ricordiamo il ruolo del compilatore tra le tecnologie informatiche, quello dell'ISA e del linguaggio assembly, i passaggi gestiti dal compilatore, dall'assembler, eccetera
\begin{itemize}
  \item Il compilatore \textbf{traduce un programma sorgente in linguaggio macchina}
  \item L'ISA agisce da "interfaccia" tra HW e SW (fornisce a SW il set di istruzioni, e specifica a HW che cosa fanno)
\end{itemize}

\subsubsection{La funzione dei compilatori}

\begin{itemize}
  \item Funzione principale e pi\`u nota: trasformare il codice \textbf{da un linguaggio ad un altro} (es. C $\rightarrow$ Assembly RISC-V) (ricordiamo che \`e solo il primo passo di un'intera toolchain di programmi per creare eseguibili)

\item Gestendo la traduzione a linguaggio macchina al posto dei programmatori, l'altra funzione importante \`e l'\textbf{ottimizzazione} del codice, che permette la \textbf{produzione di eseguibili di stesse funzionalit\`a}, ma diversi a livello di \textbf{dimensioni} (es. per sistemi embedded e high-performance), \textbf{consumo energetico}, \textbf{velocit\`a di esecuzione}, ma anche in termini di determinate \textbf{caratteristiche architetturali} utilizzate (es. proc.~multicore)
\end{itemize}

\subsubsection{L'evoluzione dei compilatori}

Le rivoluzioni in termini di "classe" di dispositivi e di dimensioni dei transistor sono molto frequenti (Bell, Moore), e nei primi 2000 si arriva ai \textbf{limiti fisici della miniaturizzazione e della frequenza} operativa dei processori (problemi di dissipazione del calore) $\rightarrow$ idea di cambiare il paradigma di sviluppo di un processore: dal singolo core sempre pi\`u potente passo a \textbf{pi\`u core "isopotenti"} sullo stesso chip
\begin{wrapfigure}{l}{.3\textwidth}
  \centering
\includegraphics[width=.25\textwidth]{intro_1.png}
\end{wrapfigure}

\noindent$\sim$ 2005: plateau di consumo, frequenza e performance di programmi \textit{sequenziali}, aumento di performance di p.~che \textbf{sfruttano la parallelizzazione} $\rightarrow$ i programmi devono essere "consapevoli" che il processore \`e multicore!\\
Il compilatore mantiene un ruolo fondamentale: oltre a rendere meno "traumatico" il passaggio alla programmazione parallela, (non sono ancora auto-parallelizzanti) si interfaccia con i nuovi paradigmi di programmazione parallela offerti ai programmatori: il programmatore sfrutta interfacce semplici e astratte, mentre il compilatore traduce i costrutti in codice parallelo eseguibile (es. OpenMP)

\subsubsection{Eterogeneit\`a architetturale}

La programmazione parallela e il parallelismo architetturale sono oggi paradigmi consolidati, e i processori general purpose (seppur multicore e ottimizzati) non sono sufficienti per attivit\`a specializzate come la grafica $\rightarrow$ nascono componenti \textbf{acceleratori} di vario tipo: GPU, GPGPU, FPGA, TPU, NPU...
Questo complica ulteriormente la scrittura del software, e dunque impone altre evoluzioni nei compilatori e nelle ottimizzazioni.

\subsection{Ottimizzazione}

Ricordiamo le metriche usate:

\noindent\begin{minipage}[c]{.5\textwidth}
\begin{equation*}
  \text{Performance} = {{1}\over\text{Execution Time}}
\end{equation*}
\end{minipage}
\begin{minipage}[c]{.5\textwidth}
\begin{equation*}
  \text{Execution Time} = {\textcolor{blue}{\text{Instruction Count}} \times \textcolor{red}{\text{CPI}} \over \textcolor{red}{\text{Frequency}}}
\end{equation*}
\end{minipage}\\

Le ottimizzazioni possono avvenire dal punto di vista \textcolor{red}{HW (parametri architetturali)} e da quello \textcolor{blue}{SW (p.~di programma)}. Il compilatore pu\`o agire anche ad es. a livello di cache, aiutando a ridurre i miss e dunque i CPI delle istruzioni \lstinline|load| e \lstinline|store| (sappiamo che il costo di accesso aumenta di ordini di grandezza)

\subsubsection{Esempi di ottimizzazione}

\begin{emphasize}
  Distinguiamo le ottimizzazioni che avvengono a compile time o a runtime (statiche o dinamiche)
\end{emphasize}

\begin{itemize}
  \item \textbf{AS (Algebraic Semplification)}Semplification: ottimizzazione a runtime
  \begin{lstlisting}
-(-i); $\rightarrow$ i;
b or true; $\rightarrow$ true; //cortocircuito logico\end{lstlisting}
  \item \textbf{CF (Constant Folding)}:  valutare ed espandere espressioni costanti a compile time
  \begin{lstlisting}
c = 1+3; $\rightarrow$ c = 4;
(100<0) $\rightarrow$ false\end{lstlisting}
  
  \item \textbf{SR (Strength Reduction)}: sostituisco op. costose con altre pi\`u semplici: classico es. \lstinline|MUL| rimpiazzate da \lstinline|ADD/SHIFT| (esecuzione in 1 ciclo invece di multic.):\\
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
y = x*2;
y = x * 17;\end{lstlisting}
  \end{minipage}
  \hfill
  $\rightarrow$
  \hfill
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
y = x+x;
y = (x<<4) + x;\end{lstlisting}
  \end{minipage}\\
  es.~sofisticato: \lstinline|for| con operazioni su array, sostituito da operazioni su puntatori (aritmetica dei pt.) $\rightarrow$ il risultato si vede nel codice assembly\\
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
for (i=0; i<100; i++)
  a[i] = i*100;
  \end{lstlisting} 
  \end{minipage}
  \hfill
$\rightarrow$
  \hfill
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
t = 0;
for (; t<10000; t += 100) {
  *a = t;
  a = a + 4;
}\end{lstlisting}
  \end{minipage}
  
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
li s0, 0 // i = 0
li s1, 100
LOOP:
bge s0, s1, EXIT
slli s2, s0, 2
add s2, s2, a0
mul s3, s0, 100
sw s3, 0(s2)
addi s0, s0, 1
jal zero, LOOP
EXIT:\end{lstlisting} 
  \end{minipage}
  \hfill
$\rightarrow$
  \hfill
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
li s0, 0 // t = 0
li s1, 10000
LOOP:
bge s0, s1, EXIT
sw s0, 0(a0)
addi a0, a0, 4
jal zero, LOOP
EXIT:\end{lstlisting}
  \end{minipage}
  
\item \textbf{CSE (Common Subexpression Elimination)}: elimino i calcoli ridondanti di una stessa espressione riutilizzata in pi\`u istruzioni (statement)\\
  \begin{minipage}[c]{.4\textwidth}
    \begin{lstlisting}
y = b * c + 4
z = b * c - 1\end{lstlisting}
  \end{minipage}
\hfill $\rightarrow$ \hfill
\begin{minipage}[c]{.4\textwidth}
\begin{lstlisting}
x = b * c
y = x + 4
z = x - 1\end{lstlisting}
\end{minipage}
\item \textbf{DCE (Dead Code Elimination)}: elimino tutte le istruzioni che producono codice mai letto (e dunque utilizzato), es. variabili assegnate e mai lette, codice irraggiungibile $\rightarrow$ uno dei passi eseguiti pi\`u di frequente durante l'ottimizzazione del codice da parte del compilatore, per rimuovere anche tutto il dead code generato dagli altri passi di ottimizzazione\\
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
b = 3
c = 1 + 3
d = 3 + c\end{lstlisting}
  \end{minipage}
  \hfill $\rightarrow$ \hfill
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
c = 1 + 3
d = 3 + c\end{lstlisting}
  \end{minipage}

  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
if (100<0)
{a = 5}\end{lstlisting}
  \end{minipage}
  \hfill $\rightarrow$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
if (false)
{}\end{lstlisting}
  \end{minipage}
  \hfill $\rightarrow$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}

  \end{lstlisting}
  \end{minipage}
\item \textbf{Copy Propagation}: per uno statement \lstinline|x = y|, sostituisco gli usi futuri di \lstinline|x| con \lstinline|y| se non sono cambiati nel frattempo (propedeutico alla DCE)\\
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
x = y;
c = 1 + x;
d = y + c;\end{lstlisting}
  \end{minipage}
  \hfill $\rightarrow$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
x = y;
c = 1 + y;
d = y + c;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{DCE}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
c = 1 + y;
d = y + c;\end{lstlisting}
  \end{minipage}
\item \textbf{CP (Constant Propagation)}: sostituisco usi futuri di una variabile con assegnato valore costante con la costante stessa (se la variabile non cambia) (sempre ipotesi che i valori a fine es.~siano poi \textbf{usati}, e non dead code)\\
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
b = 3;
c = 1 + b;
d = b + c;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{CP}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
b = 3;
c = 1 + 3;
d = 3 + c;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{CF}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
b = 3;
c = 4;
d = 3 + c;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{CP}}$ \hfill

  \hfill $\tiny\underrightarrow{\text{CP}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
b = 3;
c = 4;
d = 3 + 4;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{CF}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
b = 3;
c = 4;
d = 7;\end{lstlisting}
  \end{minipage}
  \hfill $\tiny\underrightarrow{\text{DCE}}$ \hfill
  \begin{minipage}[c]{.25\textwidth}
  \begin{lstlisting}
d = 7;\end{lstlisting}
  \end{minipage}
\item LICM (Loop Invariant Code Motion): si occupa di muovere fuori dai loop tutto il codice \textbf{loop invariant}; evita i calcoli ridondanti\\
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
while (i<100) {
  *p = x/y + i;
  i = i + 1;
}\end{lstlisting}
  \end{minipage}
  \hfill $\rightarrow$ \hfill
  \begin{minipage}[c]{.4\textwidth}
  \begin{lstlisting}
t = x + y;
while (i < 100) {
  *p = t + i;
  i = i + 1;
}\end{lstlisting}
  \end{minipage}
\end{itemize}

\subsubsection{Ottimizzazioni sui loop}

\begin{itemize}
  \item grande impatto sulla performance dell'intero programma (per ovvie ragioni)
  \item spesso sono ottimizzazioni propedeutiche a quelle machine-specific (effettuate nel backend): register allocation, instruction level parallelism, data parallelism, data-cache locality
\end{itemize}

\subsection{Anatomia di un compilatore}

\begin{figure}[h]
  \centering
  \includegraphics[width=.5\textwidth]{intro_3.png}
\end{figure}

\begin{itemize}
  \item almeno due compiti: \textbf{analisi del sorgente} e \textbf{sintesi di un programma in linguaggio macchina}, operando su una IR che si interpone tra frontend e backend, e tra source code e target code
  \item Il blocco di middle-end agisce su IR, e in vari passaggi lo trasforma e ottimizza ($\neq$ a seconda del compilatore)
  \item caso llvm: \lstinline|clang| (frontend) $\rightarrow$ \lstinline|opt| (middleend) $\rightarrow$ \lstinline|llc| (backend)
  \item \lstinline|opt| si basa su una serie di \textbf{passi di ottimizzazione (o di analisi)}: un passo di analisi scorre l'IR e lo analizza (non lo trasforma, ma produce informazioni utili); un passo di ottimizzazione sfrutta informazioni conosciute per trasformare l'IR (applica le ottimizzazione)
  \item alcune ottimizzazioni non possono essere effettuate o finalizzate senza conoscere l'architettura target (es. sulle cache), e dunque vengono eseguite dal backend
\end{itemize}

\subsubsection{Flag di ottimizzazione}

sono flag che passo al compilatore (al pass manager) per influenzare \textbf{ordine e numero dei passi di ottimizzazione}
\begin{multicols}{2}
\begin{itemize}
  \item \lstinline|-g|: solo debugging, nessuna ottimizzazione
  \item \lstinline|-O0|: nessuna ottimizzazione
  \item \lstinline|-O1|: solo ott. semplici
  \item \lstinline|-O2|: ott. pi\`u aggressive
  \item \lstinline|-O3|: ordine dei passi che sfrutta compromessi tra velocit\`a e spazio occupato
  \item \lstinline|-OS|: ottimizza per dimensione del compilato
\end{itemize}
\end{multicols}


\subsubsection{Uso di IR}

un backend che fa uso di IR permette di disaccoppiare con facilit\`a frontend e backend, lavorare su ottimizzazioni machine-independent, semplificare il supporto per molti linguaggi, eccetera

\begin{emphasize}
  Per supportare un nuovo linguaggio o una nuova architettura, basta scrivere un nuovo front/backend - il middle-end pu\`o rimanere lo stesso!
\end{emphasize}

\subsubsection{Ingredienti dell'ottimizzazione}

\begin{itemize}
  \item \textbf{formulare un problema di ottimizzazione} con molti casi di applicazione, sufficientemente efficiente e impattante su parti significative
  \item[$\rightarrow$] \textbf{rappresentazione} che astrae dettagli rilevanti $\rightarrow$ \textbf{analisi} di applicabilit\`a $\rightarrow$ \textbf{trasformazione del codice} $\rightarrow$ \textbf{testing} $\rightarrow \, \circlearrowleft$
\end{itemize}

\vspace{-2em}
\section{Rappresentazione intermedia (4 mar)}

Ricordiamo: middle end come sequenza di passi, di analisi o di trasformazione $\rightarrow$ per analizzare e trasformare il codice occorre una rappr.~intermedia (IR) \textbf{espressiva} che \textbf{mantenga le informazioni importanti da un passo all'altro}

\vspace{-1em}
\subsection{Propriet\`a di una IR}

scegliamo IR diverse a seconda del loro uso, in generale alcune caratteristiche sono sempre richieste:
\begin{itemize}
  \item facilit\`a di \textbf{generazione} (effetti sul frontend)
  \item facilit\`a e costo di \textbf{manipolazione}
  \item livello di astrazione e di \textbf{dettaglio esposto}: effetti su frontend e backend ($\neq$ IR da un lato e dall'altro, a seconda di astraz.~e dettaglio necessari)
\end{itemize}

\vspace{-1em}
\subsection{Tipi di IR}

\begin{itemize}
  \item AST (abstract syntax tree)
  \item DAG (grafi diretti aciclici)
  \item 3AC (3-address code): simile all'assembly (3 indirizzi: registro destinazione e max 2 operandi)
  \item SSA (Static Single Assignment): evoluzione di 3ac con ulteriori propriet\`a di control flow
  \item CFG (control flow graphs): rappresenta "come" vengono chiamate le funzioni (a partire dal main)
  \item CG (call graph)
  \item PDG (program dependence graphs): fondamentale per lavorare sul parallelismo, multithreading...
\end{itemize}

\vspace{-1em}
\begin{emphasize}
  Le ott.~inter-procedurali devono per forza basarsi su IR di tipo CG (es. per decidere quando fare \textbf{inlining} - espandere il codice della funzione invece di chiamarla - evidente tradeoff tra dimensione del codice e overhead dovuto alla chiamata di funzione)
\end{emphasize}

\subsection{Categorie di IR}

\begin{itemize}
  \item grafiche (o strutturali)
    \begin{itemize}
      \item orientate ai grafi
      \item molto usate nella source-to-source translation, tipicam.~per ott.~che non hanno bisogno della struttura sofisticata di un middle-end\\
      es.~openMP: di fatto annotazioni sul codice, come strumento semplice per la parall.~(es. \textbf{outlining}: prendo es un loop e lo impacchetto in una funzione che poi dovra essere eseguita dai thread per la parallelizzazione) - non sto ottimizzando nel senso proprio del termine, ma sto trasformando il codice e lo sto rendendo eseguibile in maniera parallela
      \item solitamente voluminose (basate su grafi) - tradeoff con il fatto che non coinvolgono il middle-end
      \item es. ast, dag
    \end{itemize}
  \item lineari
    \begin{itemize}
      \item pseudocodice per macchine astratte
      \item livello di astrazione vario
      \item strutture dati semplici e compatte
      \item facile da riarrangiare (evidentemente il pi\`u comodo per eseguire le ottimizzazioni)
      \item es. 3ac
    \end{itemize}
  \item ibride (sfruttano combinazioni delle prime due) (es cfg)
\end{itemize}
\subsection{Esempi di rappresentazione}


\subsubsection{Sintassi concreta (testo)}

Pi\`u semplice in quanto pi\`u vicina al livello di astrazione "umano" di ragionamento sul programma, ma non il livello corretto per ottimizzare ne comprendere correttamente la semantica del programma

\begin{lstlisting}[language=java]
let value = 8;
let result = 1;
for (let i = value; i>0; i = i - 1) {
  result = result * i;
}
console.log(result);\end{lstlisting}

\vspace{-.5em}
\subsubsection{AST}

Albero i cui nodi rappresentano diverse parti del programma: il nodo radice rappresenta il \textbf{programma}, il quale a sua volta contiene un blocco di istruzioni dal quale discendono tanti figli quante le sue istruzioni

\noindent\begin{minipage}[c]{.3\textwidth}
\includegraphics[width=\textwidth]{ir_1.png}
\end{minipage}
\begin{minipage}[c]{.7\textwidth}
\begin{lstlisting}
x = a + a * (b - c)
y = (b - c ) * d
z = x + y\end{lstlisting}
\textbf{PRO}: molto comodo per interpreti (basta usare una fz.~ricorsiva per processare l'albero)

\textbf{CONTRO}: un nodo \`e un oggetto troppo generico $\rightarrow$ analizzare un ast per l'ottimizzazione impone ogni volta di ragionare sulla differenza semantica tra i nodi (complica molto)
\end{minipage}


\vspace{-.5em}
\subsubsection{DAG}

Contrazione di ast che evita la duplicazione di espressioni $\rightarrow$ \textbf{rappresentazione pi\`u compatta}

\noindent\textbf{Limite}: il riuso e possibile solamente dimostrando che il suo \textbf{valore non cambia} nel programma
\begin{emphasize}
  essendo assegnamenti e chiamate frequentissimi, il fatto che il dag non abbia nozione di come le espr.~cambino valore nel tempo non lo rende un buon candidato per le ottimizzazioni
\end{emphasize}

\begin{example}[frametitle={Esempi}]
   \noindent\begin{minipage}[c]{.2\textwidth}
   \includegraphics[width=\textwidth]{ir_2.png}
   \end{minipage}
   \begin{minipage}[c]{.23\textwidth}
      \begin{lstlisting}
x = a+a*(b-c);
y = (b-c)*d;
z = x+y;
# espr. trovate
t1 = b-c;
t2 = a*t1;
x = a+t2;
y = t1*d;
z = x+y;\end{lstlisting}
   \end{minipage}\hfill\vline
   \begin{minipage}[c]{.2\textwidth}
   \includegraphics[width=\textwidth]{ir_3.png}
   \end{minipage}
   \begin{minipage}[c]{.35\textwidth}
      \begin{lstlisting}
a = b + c;
b = a - d;
c = b + c;
d = a - d;
# espr. trovate (ERRORE)
a = b + c; # cambia val.
d = a - d;
c = d + c;\end{lstlisting}
   \end{minipage}
\end{example}



\subsubsection{3AC}

Evidentemente adatto: tutte le istr.~del programma vengono spezzettate in istr.~di forma semplice simile all'assembly, di tipo \lstinline|x = y op z| (1 operatore, massimo 3 operandi)

esempio:

\lstinline|x - 2 * y| $\rightarrow$ \lstinline|t1 = |

\textbf{PRO}:
\begin{itemize}
  \item espressioni complesse spezzettate
  \item forma compatta e simil-assembly
  \item introdotti registri temporanei intermedi, virtuali e illimitati (non mi preoccupo di problemi architetturali - quanti r.~fisici ho a disposizione) (non gestisco eventuali op. di spill - aggiungere load o store in mancanza di r.~fisici)
\end{itemize}

rec

\paragraph{varianti di 3ac}~\\

varianti a seconda dei vincoli che ho per l'implementazione pratica

quadruple: id istruzione, opcode, i 3 registri (semplice struttura record, facile da analizzare e riordinare ma i nomi espliciti prendono pi\`u spazio)
triple: id istruzione, opcode, 2 operandi $\rightarrow$ uso l'indice dell'espressione nell'array come "nome" del registro destinazione $\rightarrow$ risparmio spazio, ma diventa piu complesso da analizzare (nomi impliciti) e soprattutto da riordinare


ricordiamo la constant propagation: sostituisco usi futuri di una variabile con valore costante con la costante stessa \textbf{se non cambia nel frattempo}

$\rightarrow$ ottimizzazione che una IR di tipo 3ac non puo applicare immediatamente (devo prima analizzare il resto del codice) $\rightarrow$ SSA come evoluzione della 3ac, in quanto impone che la \textbf{definizione (assegnamento)} delle variabili avvenga \textbf{solo una volta} (definizioni multiple sono tradotte in multiple versioni della var)

pro: ogni definizione ha associata direttamente una lista di tutti i suoi usi - semplifica enormemente le ottimizzazioni di tipo CP e non solo

quasi sempre uno dei passi di ottimizzazione prevede il passaggio a forma SSA

\begin{emphasize}
  La scelta della IR dipende ovviamente dal livello di dettaglio necessario per ogni specifico compito $\rightarrow$ \textbf{in un compilatore coesistono pi\`u IR}

  \noindent Anche per questo ci sono le forme ibride - es. cfg con 3ac
\end{emphasize}

\subsubsection{cfg}

vediamo un esempio con costrutti condizionali (non solo sequenze lineari)

immagine slide 2-28

un cfg permette di aggiungere informazioni sui \textbf{salti} al di sopra di una IR lineare $\rightarrow$ modello il flusso di controllo del programma come grafo composto da blocchi (BB)

ogni bb contiene sequenze lineari di istruzioni

gli archi rappresentano il flusso di controllo del programma


formalmente: un BB \`e una seq.~di istruzioni in forma 3AC
\begin{itemize}
  \item solo la prima istruzione puo essere raggiunta dall'esterno (garantito un singolo entry point)
  \item singolo exit point: se eseguo la prima istr.~\textbf{devo eseguire tutte le altre} - garantisco che venga eseguito interamente
\end{itemize}

le chiamiamo sezioni single-entry, single-exit (possono essere sezioni anche piu grandi, ma le piu piccole di questo tipo sono i BB)

un arco connette due nodi s.s.se il secondo puo eseguire dopo il primo in qualche percorso del ctrl flow del programma (prima istr del secondo \`e target dell'istr di salto al termine del primo, oppure il secondo \`e l'unico successore del primo che non ha un istr di salto come ultima istr - il secondo lo chiamo nodo falltrough)

un cfg \textbf{normalizzato} ha i bb \textbf{massimali} (non possono essere resi piu grandi senza violare condizioni) (unisco i bb fallthrough che non hanno label all'inizio, evidentemente) (situazioni di cfg non normalizzato possono avvenire dopo qualche generico passo di ottimizzazione, evidentemente non le facciamo accadere noi "spontaneamente")

\paragraph{algoritmo per la costruzione del cfg}~\\

\begin{enumerate}
  \item identificare il \textbf{leader} di ogni bb:
    \begin{itemize}
      \item la prima istruzione
      \item il target di un salto
      \item ogni istruzione dopo un salto
    \end{itemize}
  \item il bb comincia con il leader e termina con l'istruzione immediatamente precedente un nuovo leader (o l'ultima istruzione)
  \item connettere i bb tramite archi di 3 tipi:
    \begin{itemize}
      \item fallthrough (o fallthru): esiste solo un percorso che collega i due blocchi
      \item true: il secondo blocco \`e raggiungibile dal primo se un condizionale \`e true
      \item false: il secondo blocco \`e raggiungibile dal primo se un condizionale \`e false
    \end{itemize}
    
\end{enumerate}

esempi ed esercizi fino slide 52

\subsubsection{dependency graph}

soprattutto nell'erad ei nulticore questa rappr assume sempre piu importanza

almeno due tipi: (recupera questa cosa)

ricordiamo pipeline riscv e data hazard: il fatto che un registro voglia leggere da un registro usato in un'op precedente (e non ancora salvato? recupera)

if id exe mem wb le fasi di pipelining

esempio con una mul: ricordiamo che se la mul successiva prova a usare il registro usato nell'istr prima (dipendenza), il risultato ancora non e stato scritto - nella fase di decode identifico i registri usati nell'operazione, e appunto rw ancora non contiene il risultato aggiornato, che sara pronto appena tra 2 cicli

questo e un data hazard, nel caso comune si gestisce con una \textbf{forwarding unit} che bypassa le fasi successive e inoltra direttamente il risultato appena ottenuto

per quanto la fw unit sia un pezzo di hw dedicato che fa questi controlli autonomamente, in generale l'unico modo per evitare questo tipo di hazard \`e distanziare abbastanza le istruzioni tra loro affinche il dato sia disponibile $\rightarrow$ sposto l'istruzione di mul inserendo nop (cicli di stallo) (evidentemente non buono - vado a "rompere" l'IPC paria a 1 della pipeline sempre piena, evidentemente diminuisce la performance)

soluzione migliore: scheduling del programma, ovvero sposto istruzioni che non hanno bisogno di quei registri per riempire quello spazio altrimenti occupato necessariamente da nop

questo \`e uno dei compiti principali di un backend - \textbf{in che ordine genero le istruzioni per massimizzare l'efficienza del programma}

come faccio a fare questa cosa? manualmente: vado a guardare le istruzioni e cerco a mano le dipendenze; il backend sfrutta la IR di tipo dg che fornisce esattamente le informazioni sulle dipendenze tra istruzioni

qui si capisce cosa si intende per instruction level parallelism: dunque, quando \`e possibile sfruttare tutte le parti di architettura per "parallelizzare il codice" anche in caso di single thread (ottimizzazione senza reale parallelismo)


\subsubsection{data dependency graph ddg}

Specifico per multicore e parallelismo, usato per dare una rappresentazione tra le dipendenze dei \textbf{dati} - tipicamente i loop

per esempio, (loop innestati lavorano tipicamente su str dati complesse e multidimensionali (matrici, immagini, ecc.))

\begin{lstlisting}
for (i = 0, i < n, i++)
  A[i]=init();
\end{lstlisting}


Ogni it. resta indipendente dalle altre (uso il solo indice del loop) - basta aggiungere ad es.~ \lstinline|A[i-1] = A[i]| per generare dipendenze tra le iterazioni $\rightarrow$ il loop non \`e pi\`u parallelizzabile, e deve per forza essere eseguito in sequenza

Data la complessit\`a delle casistiche reali,  esistono vari modi per rappresentare lo spazio delle iterazioni di un loop e le dipendenze che ne derivano:\\
all'oggi usiamo il \textbf{polyhedral model} $\rightarrow$ rappresento lo spazio delle it.~come un poliedro (a seconda del numero di loop innestati), che permette di capire se esiste qualche permutazione dei loop (direzione di attraversamento dello spazio delle iterazioni; ovvero ad esempio scambiare l'ordine dei loop) non soggetta a dipendenze

\subsubsection{call graph}

rappresetnazione grafica a grafo usata per ragionare sulle relazione tra le funzioni della translation unit del file (insieme delle potenziali chiamate tra funzioni)

rappr.~gerarchica, utile soprattutto a livello di analisi \textbf{interprocedurale} (la maggior parte delle ottimizzazioni avvengono a livello \textit{intraprocedurale}) (recupera questo concetto) (lavora sui file che abbiamo chiamato translation units, ovvero quelli da cui poi genero i file oggetto)

$\rightarrow$ evidente come il compilatore abbia visibilita solo fino a livello dei singoli moduli: posso estendere le ottimizzazioni al massimo fino ai legami tra funzioni dello stesso modulo - le ottimizzazioni piu ampie si spostano a framework di ottimizzazione che agiscono a livello di linker per esempio

\end{document}
